{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Example\n",
    "This notebook demonstrates how to use the pruning methods from this tool to compress a model. \n",
    "\n",
    "The example uses the MNIST dataset and a simple CNN model. The model is trained and then pruned using the methods in this tool. The pruned model is then evaluated on the test set to see how well it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define pytorch model\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "import importlib\n",
    "import inspect\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add thesis package to path\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import src.general as general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "no_cuda = False\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "print(f\"Using cuda: {use_cuda}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "model_state = \"../models/mnist.pt\"\n",
    "model_class = \"models.mnist\"\n",
    "\n",
    "# Import the module classes\n",
    "module = importlib.import_module(model_class)\n",
    "classes = general.get_module_classes(module)\n",
    "for cls in classes:\n",
    "    globals()[cls.__name__] = cls\n",
    "\n",
    "# Get device\n",
    "device = general.get_device()\n",
    "\n",
    "# Load the model\n",
    "model = torch.load(model_state, map_location=torch.device(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data loaders for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "use_cuda = False\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "mnist_transform = transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=mnist_transform,),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=mnist_transform,),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and test methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 3\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.general failed: Traceback (most recent call last):\n",
      "  File \"/Users/abel/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/abel/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/abel/miniconda3/envs/torch-gpu/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/abel/miniconda3/envs/torch-gpu/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 976, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 906, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/abel/Development/thesis/examples/../src/general.py\", line 18\n",
      "    for batch_id, (data, target) in enumerate(tqdm(train_loader, desc='Train'):\n",
      "                                                                              ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n",
      "Train: 100%|██████████| 938/938 [00:20<00:00, 44.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== TRAIN PERFORMANCE ==============================\n",
      "Average loss = 0.0914\n",
      "Elapsed time = 20909.89 milliseconds (22.29 per batch, 0.70 per data point)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:01<00:00, 135.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== TEST PERFORMANCE ===============================\n",
      "Average loss = 0.1821\n",
      "Elapsed time = 1156.89 milliseconds (7.37 per batch, 0.46 per data point)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 938/938 [00:20<00:00, 45.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== TRAIN PERFORMANCE ==============================\n",
      "Average loss = 0.1091\n",
      "Elapsed time = 20454.45 milliseconds (21.81 per batch, 0.68 per data point)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:01<00:00, 135.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== TEST PERFORMANCE ===============================\n",
      "Average loss = 0.1095\n",
      "Elapsed time = 1156.83 milliseconds (7.37 per batch, 0.46 per data point)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 938/938 [00:20<00:00, 45.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== TRAIN PERFORMANCE ==============================\n",
      "Average loss = 0.0772\n",
      "Elapsed time = 20807.45 milliseconds (22.18 per batch, 0.69 per data point)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:01<00:00, 145.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== TEST PERFORMANCE ===============================\n",
      "Average loss = 0.0785\n",
      "Elapsed time = 1077.15 milliseconds (6.86 per batch, 0.43 per data point)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from models.mnist import MnistModel\n",
    "from src.general import train, test\n",
    "\n",
    "model = MnistModel().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = F.nll_loss\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, criterion, optimizer)\n",
    "    test(model, device, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "save_model_path = \"../models/mnist.pt\"\n",
    "\n",
    "if save_model:\n",
    "    torch.save(model, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test() missing 2 required positional arguments: 'criterion' and 'epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zw/6683d62105s8pxz87x2_ny900000gn/T/ipykernel_36099/486598545.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test model performance before pruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before pruning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define the parameters to prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test() missing 2 required positional arguments: 'criterion' and 'epoch'"
     ]
    }
   ],
   "source": [
    "# Test model performance before pruning\n",
    "print(\"Before pruning\")\n",
    "test(model, device, test_loader)\n",
    "\n",
    "# Define the parameters to prune\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.95,\n",
    ")\n",
    "\n",
    "# Test model performance after pruning\n",
    "print(\"After pruning\")\n",
    "test(model, device, test_loader)\n",
    "\n",
    "# Print number of parameters in model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "\n",
    "\n",
    "# Print number of parameters pruned\n",
    "total_pruned_params = sum(p.numel() for p in model.parameters() if hasattr(p, 'mask'))\n",
    "print(f'{total_pruned_params:,} parameters pruned ({100 * total_pruned_params / total_params:.2f}% pruned)')\n",
    "\n",
    "# Print number of parameters remaining\n",
    "total_unpruned_params = sum(p.numel() for p in model.parameters() if not hasattr(p, 'mask'))\n",
    "print(f'{total_unpruned_params:,} parameters unpruned ({100 * total_unpruned_params / total_params:.2f}% unpruned)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff67d639abb31abb6a46275810293efc60456a6edbd614d8502142bf104bd3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
