{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Example\n",
    "This notebook demonstrates how to use the pruning methods from this tool to compress a model. \n",
    "\n",
    "The example uses the MNIST dataset and a simple CNN model. The model is trained and then pruned using the methods in this tool. The pruned model is then evaluated on the test set to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define pytorch model\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "import importlib\n",
    "import inspect\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add thesis package to path\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import src.general as general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "no_cuda = False\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "print(f\"Using cuda: {use_cuda}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "model_state = \"../models/mnist.pt\"\n",
    "model_class = \"models.mnist\"\n",
    "\n",
    "# Import the module classes\n",
    "module = importlib.import_module(model_class)\n",
    "classes = general.get_module_classes(module)\n",
    "for cls in classes:\n",
    "    globals()[cls.__name__] = cls\n",
    "\n",
    "# Get device\n",
    "device = general.get_device()\n",
    "\n",
    "# Load the model\n",
    "model = torch.load(model_state, map_location=torch.device(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data loaders for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "use_cuda = False\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "mnist_transform = transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=mnist_transform,),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=mnist_transform,),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and test methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 3\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t Distillation Loss: 0.0996\n",
      "Train Epoch: 1 [6400/60000 (11%)]\t Distillation Loss: 0.0621\n",
      "Train Epoch: 1 [12800/60000 (21%)]\t Distillation Loss: 0.0587\n",
      "Train Epoch: 1 [19200/60000 (32%)]\t Distillation Loss: 0.0725\n",
      "Train Epoch: 1 [25600/60000 (43%)]\t Distillation Loss: 0.0051\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t Distillation Loss: 0.0316\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t Distillation Loss: 0.1369\n",
      "Train Epoch: 1 [44800/60000 (75%)]\t Distillation Loss: 0.0556\n",
      "Train Epoch: 1 [51200/60000 (85%)]\t Distillation Loss: 0.0113\n",
      "Train Epoch: 1 [57600/60000 (96%)]\t Distillation Loss: 0.1007\n",
      "========================================= PERFORMANCE =============================================\n",
      "Train Set: Average loss: 0.0288\n",
      "Elapsed time = 20047.72 milliseconds (21.37 per batch)\n",
      "====================================================================================================\n",
      "Test Epoch: 1 [0/10000 (0%)]\tLoss: 0.021109\n",
      "Test Epoch: 1 [6400/10000 (64%)]\tLoss: 0.157729\n",
      "Test Epoch: 1 [2496/10000 (99%)]\tLoss: 0.050407\n",
      "========================================= PERFORMANCE =============================================\n",
      "Test Set: Average loss: 0.0430\n",
      "Elapsed time = 1064.78 milliseconds (6.78 per batch)\n",
      "====================================================================================================\n",
      "Train Epoch: 2 [0/60000 (0%)]\t Distillation Loss: 0.0174\n",
      "Train Epoch: 2 [6400/60000 (11%)]\t Distillation Loss: 0.0695\n",
      "Train Epoch: 2 [12800/60000 (21%)]\t Distillation Loss: 0.0324\n",
      "Train Epoch: 2 [19200/60000 (32%)]\t Distillation Loss: 0.0287\n",
      "Train Epoch: 2 [25600/60000 (43%)]\t Distillation Loss: 0.0439\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t Distillation Loss: 0.0092\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t Distillation Loss: 0.0273\n",
      "Train Epoch: 2 [44800/60000 (75%)]\t Distillation Loss: 0.0597\n",
      "Train Epoch: 2 [51200/60000 (85%)]\t Distillation Loss: 0.0428\n",
      "Train Epoch: 2 [57600/60000 (96%)]\t Distillation Loss: 0.0047\n",
      "========================================= PERFORMANCE =============================================\n",
      "Train Set: Average loss: 0.0059\n",
      "Elapsed time = 20594.66 milliseconds (21.96 per batch)\n",
      "====================================================================================================\n",
      "Test Epoch: 2 [0/10000 (0%)]\tLoss: 0.067384\n",
      "Test Epoch: 2 [6400/10000 (64%)]\tLoss: 0.010602\n",
      "Test Epoch: 2 [2496/10000 (99%)]\tLoss: 0.004289\n",
      "========================================= PERFORMANCE =============================================\n",
      "Test Set: Average loss: 0.0441\n",
      "Elapsed time = 1066.49 milliseconds (6.79 per batch)\n",
      "====================================================================================================\n",
      "Train Epoch: 3 [0/60000 (0%)]\t Distillation Loss: 0.1036\n",
      "Train Epoch: 3 [6400/60000 (11%)]\t Distillation Loss: 0.0185\n",
      "Train Epoch: 3 [12800/60000 (21%)]\t Distillation Loss: 0.1007\n"
     ]
    }
   ],
   "source": [
    "from models.mnist import MnistModel\n",
    "from src.general import train, test\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = F.nll_loss\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, criterion, optimizer, epoch)\n",
    "    test(model, device, test_loader, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "save_model_path = \"../models/mnist.pt\"\n",
    "\n",
    "if save_model:\n",
    "    torch.save(model, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test() missing 2 required positional arguments: 'criterion' and 'epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zw/6683d62105s8pxz87x2_ny900000gn/T/ipykernel_34415/486598545.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test model performance before pruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before pruning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define the parameters to prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test() missing 2 required positional arguments: 'criterion' and 'epoch'"
     ]
    }
   ],
   "source": [
    "# Test model performance before pruning\n",
    "print(\"Before pruning\")\n",
    "test(model, device, test_loader)\n",
    "\n",
    "# Define the parameters to prune\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.95,\n",
    ")\n",
    "\n",
    "# Test model performance after pruning\n",
    "print(\"After pruning\")\n",
    "test(model, device, test_loader)\n",
    "\n",
    "# Print number of parameters in model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "\n",
    "\n",
    "# Print number of parameters pruned\n",
    "total_pruned_params = sum(p.numel() for p in model.parameters() if hasattr(p, 'mask'))\n",
    "print(f'{total_pruned_params:,} parameters pruned ({100 * total_pruned_params / total_params:.2f}% pruned)')\n",
    "\n",
    "# Print number of parameters remaining\n",
    "total_unpruned_params = sum(p.numel() for p in model.parameters() if not hasattr(p, 'mask'))\n",
    "print(f'{total_unpruned_params:,} parameters unpruned ({100 * total_unpruned_params / total_params:.2f}% unpruned)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff67d639abb31abb6a46275810293efc60456a6edbd614d8502142bf104bd3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
