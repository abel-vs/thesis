{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Example\n",
    "This notebook demonstrates how to use the pruning methods from this tool to compress a model. \n",
    "\n",
    "The example uses the MNIST dataset and a simple CNN model. The model is trained and then pruned using the methods in this tool. The pruned model is then evaluated on the test set to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define pytorch model\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "A model architecture needs to be defined. This can be an existing model, from e.g. Hugginface, or a custom created one.\n",
    "Here we create a basic CNN model as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the basic components for the training and testing of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "no_cuda = False\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "print(f\"Using cuda: {use_cuda}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Define model, optimizer, and criterion\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set basic parameters for the training and testing of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "save_model = True\n",
    "save_model_path = \"./save/mnist_cnn.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to load data\n",
    "def get_train_test_split(batch_size, test_batch_size):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "        \n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the training function\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "#Define the test function\n",
    "def test(model, device, test_loader, criterion):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "\n",
    "    # Disable gradients (to save memory)\n",
    "    with torch.no_grad():\n",
    "        # Loop over batches of test data\n",
    "        for inputs, labels in test_loader:\n",
    "            # Move data to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update test loss and accuracy\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (outputs.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the main function\n",
    "def main():\n",
    "\n",
    "    train_loader, test_loader = get_train_test_split(batch_size, test_batch_size)\n",
    "\n",
    "    # Load model from file\n",
    "    model = None\n",
    "    if os.path.exists(save_model_path):\n",
    "        model = torch.load(save_model_path).to(device)\n",
    "    # If model is not loaded from file, create a new model\n",
    "    if model is None:\n",
    "        model = Net().to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    # Use the profiler to profile the model's execution\n",
    "    with torch.autograd.profiler.profile() as prof:\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(model, device, train_loader, optimizer, epoch)\n",
    "            test(model, device, test_loader)\n",
    "\n",
    "    # Print the profiler results\n",
    "    # print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model,save_model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning\n",
      "Test set: Average loss: 0.0356, Accuracy: 9882/10000 (99%)\n",
      "After pruning\n",
      "Test set: Average loss: 0.3147, Accuracy: 9496/10000 (95%)\n",
      "431,080 total parameters.\n",
      "0 parameters pruned (0.00% pruned)\n",
      "431,080 parameters unpruned (100.00% unpruned)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loader = get_train_test_split(batch_size, test_batch_size)[1]\n",
    "\n",
    "\n",
    "# Test model performance before pruning\n",
    "print(\"Before pruning\")\n",
    "test(model, device, test_loader)\n",
    "\n",
    "# Define the parameters to prune\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.95,\n",
    ")\n",
    "\n",
    "# Test model performance after pruning\n",
    "print(\"After pruning\")\n",
    "test(model, device, test_loader)\n",
    "\n",
    "# Print number of parameters in model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "\n",
    "\n",
    "# Print number of parameters pruned\n",
    "total_pruned_params = sum(p.numel() for p in model.parameters() if hasattr(p, 'mask'))\n",
    "print(f'{total_pruned_params:,} parameters pruned ({100 * total_pruned_params / total_params:.2f}% pruned)')\n",
    "\n",
    "# Print number of parameters remaining\n",
    "total_unpruned_params = sum(p.numel() for p in model.parameters() if not hasattr(p, 'mask'))\n",
    "print(f'{total_unpruned_params:,} parameters unpruned ({100 * total_unpruned_params / total_params:.2f}% unpruned)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Use Case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 21:12:53) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ddbabd33cf547a84c11eb408eb3c9b7be4eb2afd7a6d10ca77341cb1226f34b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
