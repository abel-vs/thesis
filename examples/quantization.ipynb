{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization\n",
    "This notebook acts as an example of how to use the quantization techniques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "* Import the necessary packages.\n",
    "* Load a model.\n",
    "* Load a dataset.\n",
    "* Analyze performance of the model prior to quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import inspect\n",
    "import sys\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add thesis package to path\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import src.general as general\n",
    "import src.metrics as metrics\n",
    "import src.evaluation as eval\n",
    "import src.compression.quantization as quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "model_state = \"../models/mnist.pt\"\n",
    "model_class = \"models.mnist\"\n",
    "\n",
    "# Import the module classes\n",
    "module = importlib.import_module(model_class)\n",
    "classes = general.get_module_classes(module)\n",
    "for cls in classes:\n",
    "    globals()[cls.__name__] = cls\n",
    "\n",
    "# Get device\n",
    "device = general.get_device()\n",
    "\n",
    "# Load the model\n",
    "model = torch.load(model_state, map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "use_cuda = False\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "mnist_transform = transforms.ToTensor()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=mnist_transform,),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=mnist_transform,),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(loss, score, batch_duration, data_duration, batch_size, model):\n",
    "    print(\"Loss: {:.6f}\".format(loss))\n",
    "    print(\"Score: {:.6f}\".format(score))\n",
    "    print(\"Time per batch: {:.4f} ms ({} per batch)\".format(batch_duration, batch_size))\n",
    "    print(\"Time per data point: {:.4f} ms\".format(data_duration))\n",
    "    params = eval.get_model_parameters(model)\n",
    "    print('Number of parameters: {}'.format(params))\n",
    "    model_size = eval.get_model_size(model)\n",
    "    print('Model Size: {} MB'.format(model_size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Quantization Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 60/60 [00:04<00:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== TEST PERFORMANCE ===============================\n",
      "Average loss = 0.0768\n",
      "Accuracy = 0.9770\n",
      "Elapsed time = 4494.62 milliseconds (74.91 per batch, 0.07 per data point)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = F.nll_loss\n",
    "\n",
    "loss, score, duration, batch_duration, data_duration = general.test(model, device, test_loader, criterion, metric=metrics.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.076818\n",
      "Score: 0.976983\n",
      "Time per batch: 74.9103 ms (1000 per batch)\n",
      "Time per data point: 0.0749 ms\n",
      "Number of parameters: 431080\n",
      "Model Size: 1.65 MB\n"
     ]
    }
   ],
   "source": [
    "print_metrics(loss, score, batch_duration, data_duration, test_batch_size, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantization\n",
    "Here the model’s weights are pre-quantized; the activations are quantized on-the-fly (“dynamic”) during inference. \n",
    "\n",
    "Currently only Linear and Recurrent (LSTM, GRU, RNN) layers are supported for dynamic quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W TensorImpl.h:1408] Warning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (function operator())\n"
     ]
    }
   ],
   "source": [
    "dynamic_quantized_model = quant.dynamic_quantization(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 60/60 [00:04<00:00, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== TEST PERFORMANCE ===============================\n",
      "Average loss = 0.0766\n",
      "Accuracy = 0.9770\n",
      "Elapsed time = 4357.64 milliseconds (72.63 per batch, 0.07 per data point)\n",
      "================================================================================\n",
      "Loss: 0.076646\n",
      "Score: 0.976983\n",
      "Time per batch: 72.6273 ms (1000 per batch)\n",
      "Time per data point: 0.0726 ms\n",
      "Number of parameters: 25570\n",
      "Model Size: 0.49 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss, score, duration, batch_duration, data_duration = general.test(dynamic_quantized_model, device, test_loader, criterion, metric=metrics.accuracy)\n",
    "print_metrics(loss, score, batch_duration, data_duration, test_batch_size, dynamic_quantized_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Quantization\n",
    "Post Training Static Quantization (PTQ) also pre-quantizes model weights but instead of calibrating activations on-the-fly, the clipping range is pre-calibrated and fixed (“static”) using validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 938/938 [00:06<00:00, 138.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== TEST PERFORMANCE ===============================\n",
      "Average loss = 0.0769\n",
      "Elapsed time = 6758.17 milliseconds (7.20 per batch, 0.23 per data point)\n",
      "================================================================================\n",
      "Post Training Quantization: Calibration done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/abel/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/ao/quantization/utils.py:280: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "static_quantized_model = quant.static_quantization(model, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, score, duration, batch_duration, data_duration = general.test(static_quantized_model, device, test_loader, criterion, metric=metrics.accuracy)\n",
    "print_metrics(loss, score, batch_duration, data_duration, test_batch_size, static_quantized_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff67d639abb31abb6a46275810293efc60456a6edbd614d8502142bf104bd3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
