{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation\n",
    "This notebook shows how the tool can be used to perform knowledge distillation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "* Import dependencies\n",
    "* Import data loaders\n",
    "* Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import importlib\n",
    "import inspect\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add thesis package to path\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import src.general as general\n",
    "import src.compression.distillation as distill\n",
    "import src.metrics as metrics\n",
    "import src.evaluation as eval\n",
    "import src.plot as plot\n",
    "import src.dataset_models as data\n",
    "from models.mnist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device\n",
    "device = general.get_device()\n",
    "\n",
    "# Load the dataset\n",
    "dataset = data.supported_datasets[\"MNIST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_state = \"../models/mnist.pt\"\n",
    "teacher_model = torch.load(model_state, map_location=torch.device(device))\n",
    "print(teacher_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation\n",
    "The original model acts as the teacher model. \n",
    "\n",
    "For the student model the user can either give a model architecture of their own, presented in a `.py` file, or use the the tool to intelligently design a student model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  10%|█         | 97/938 [00:02<00:22, 37.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pvanstee\\Development\\thesis\\examples\\distillation.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pvanstee/Development/thesis/examples/distillation.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m student_model \u001b[39m=\u001b[39m distill\u001b[39m.\u001b[39;49mcreate_student_model(teacher_model, dataset, fineTune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pvanstee/Development/thesis/examples/distillation.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(teacher_model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pvanstee/Development/thesis/examples/distillation.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(student_model)\n",
      "File \u001b[1;32mc:\\Users\\pvanstee\\Development\\thesis\\examples\\..\\src\\compression\\distillation.py:113\u001b[0m, in \u001b[0;36mcreate_student_model\u001b[1;34m(teacher_model, dataset, fineTune)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_student_model\u001b[39m(teacher_model, dataset: DataSet, fineTune\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    112\u001b[0m     teacher_model \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(teacher_model)\n\u001b[1;32m--> 113\u001b[0m     prune\u001b[39m.\u001b[39;49mmagnitude_pruning_structured(teacher_model, dataset, sparsity\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, fineTune\u001b[39m=\u001b[39;49mfineTune)\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m teacher_model\n",
      "File \u001b[1;32mc:\\Users\\pvanstee\\Development\\thesis\\examples\\../src\\compression\\pruning.py:97\u001b[0m, in \u001b[0;36mmagnitude_pruning_structured\u001b[1;34m(model, dataset, sparsity, fineTune)\u001b[0m\n\u001b[0;32m     95\u001b[0m     pruner\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m fineTune:\n\u001b[1;32m---> 97\u001b[0m         general\u001b[39m.\u001b[39;49mtrain(model, dataset)\n\u001b[0;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\pvanstee\\Development\\thesis\\examples\\../src\\general.py:42\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataset, optimizer)\u001b[0m\n\u001b[0;32m     40\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[0;32m     41\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 42\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     43\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m metric \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "student_model = distill.create_student_model(teacher_model, dataset, fineTune=True)\n",
    "print(teacher_model)\n",
    "print(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:01<00:00, 91.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ TEST PERFORMANCE ==============================\n",
      "Average loss = 0.0778\n",
      "Accuracy = 97.6115\n",
      "Elapsed time = 1716.67 milliseconds (10.93 per batch, 0.68 per data point)\n",
      "================================================================================\n",
      "Could not calculate FLOPS\n",
      "==================================== RESULTS ===================================\n",
      "Loss: 0.077825\n",
      "Score: 97.611465\n",
      "Time per data point: 0.6834 ms\n",
      "Model Size: 1.65 MB\n",
      "Number of parameters: 431080\n",
      "Number of FLOPs: -1\n",
      "Number of MACs: 2307728\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test performance of student model before training\n",
    "teacher_results = eval.get_results(teacher_model, dataset)\n",
    "plot.print_results(**teacher_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distillation Training: 100%|██████████| 938/938 [00:15<00:00, 58.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6245, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_criterion = F.mse_loss\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.01)\n",
    "\n",
    "distill.train(teacher_model, student_model, dataset.train_loader, distil_criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'performance_target': 99, 'fineTune': False, 'epochs': 5}\n",
      "============================= CREATING STUDENT MODEL ===========================\n",
      "Fine-tuning: False\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================ PERFORMING DISTILLATION ===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distillation Validation: 100%|██████████| 157/157 [00:01<00:00, 115.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11945149836361788, Test score: 96.89490445859873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distillation Training: 100%|██████████| 938/938 [00:16<00:00, 57.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation loss: 5.034704208374023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distillation Validation: 100%|██████████| 157/157 [00:01<00:00, 119.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.39766418582694546, Test score: 87.84832802547771\n",
      "Stopped training because score started decreasing: from 96.89490445859873 to 87.84832802547771\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"performance_target\": 99,\n",
    "    \"fineTune\": False,\n",
    "    \"epochs\": 5,\n",
    "}\n",
    "\n",
    "distilled_model = distill.perform_distillation(teacher_model, dataset, settings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Analyze the metrics of the new student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:01<00:00, 115.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0925\n",
      "Test score: 97.0939\n",
      "Could not calculate FLOPS\n",
      "============================= RESULTS BEFORE & AFTER ===========================\n",
      "Loss: 0.077825 -> 0.092510 (18.87%)\n",
      "Score: 97.611465 -> 97.093949 (-0.53%)\n",
      "Time per data point: 0.6834 ms -> 0.5410 ms (-20.84%)\n",
      "Model Size: 1.65 MB -> 0.42 MB (-74.55%)\n",
      "Number of parameters: 431080 -> 109295 (-74.65%)\n",
      "Number of FLOPs: -1 -> -1 (-0.00%)\n",
      "Number of MACs: 2307728 -> 653864 (-71.67%)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "student_results = eval.get_results(student_model, dataset)\n",
    "plot.print_before_after_results(teacher_results, student_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff67d639abb31abb6a46275810293efc60456a6edbd614d8502142bf104bd3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
