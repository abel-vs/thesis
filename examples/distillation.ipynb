{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation\n",
    "This notebook shows how the tool can be used to perform knowledge distillation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "* Import dependencies\n",
    "* Import data loaders\n",
    "* Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import importlib\n",
    "import inspect\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add thesis package to path\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import src.general as general\n",
    "import src.compression.distillation as distill\n",
    "import src.metrics as metrics\n",
    "import src.evaluation as eval\n",
    "from models.mnist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "use_cuda = False\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "mnist_transform = transforms.ToTensor()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=mnist_transform,),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=mnist_transform,),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda: False\n"
     ]
    }
   ],
   "source": [
    "model_state = \"../models/mnist.pt\"\n",
    "\n",
    "device = general.get_device()\n",
    "teacher_model = torch.load(model_state, map_location=torch.device(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation\n",
    "The original model acts as the teacher model. \n",
    "\n",
    "For the student model the user can either give a model architecture of their own, presented in a `.py` file, or use the the tool to intelligently design a student model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the student model\n",
    "student_model = MnistSmallLinear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 60/60 [00:01<00:00, 33.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= TEST SET PERFORMANCE =============================\n",
      "Average loss = 1.0869\n",
      "Metric = 93.6567\n",
      "Elapsed time = 1804.57 milliseconds (30.08 per batch)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test performance of student model before training\n",
    "general.test(student_model, device,  test_loader, criterion=F.nll_loss, epoch=1, metric = lambda x,y: metrics.accuracy_topk(x,y,topk=(1,))[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distillation Training: 100%|██████████| 7500/7500 [00:14<00:00, 534.42it/s]\n",
      "Distillation Validation: 100%|██████████| 60/60 [00:01<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Distillation loss: 8.534667015075684\n",
      "Test loss: 0.23944689904650052, Test accuracy: 0.9275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distillation Training: 100%|██████████| 7500/7500 [00:13<00:00, 542.57it/s]\n",
      "Distillation Validation: 100%|██████████| 60/60 [00:01<00:00, 35.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Distillation loss: 9.362382888793945\n",
      "Test loss: 0.21923532833655676, Test accuracy: 0.9334333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distillation Training: 100%|██████████| 7500/7500 [00:13<00:00, 553.72it/s]\n",
      "Distillation Validation: 100%|██████████| 60/60 [00:01<00:00, 34.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Distillation loss: 6.561781406402588\n",
      "Test loss: 0.21379839802781742, Test accuracy: 0.9365666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 3\n",
    "lr = 0.01\n",
    "\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=lr) # Important: use the student model parameters\n",
    "distil_criterion = F.mse_loss\n",
    "eval_criterion = F.cross_entropy\n",
    "\n",
    "\n",
    "distill.distillation_train_loop(teacher_model, student_model, train_loader, test_loader, distil_criterion, eval_criterion, optimizer, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Analayze the metrics of the new student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 60/60 [00:04<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= TEST SET PERFORMANCE =============================\n",
      "Average loss = 0.0363\n",
      "Accuracy = 0.9891\n",
      "Elapsed time = 4448.19 milliseconds (74.14 per batch)\n",
      "================================================================================\n",
      "Student model performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 60/60 [00:01<00:00, 33.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= TEST SET PERFORMANCE =============================\n",
      "Average loss = 1.3392\n",
      "Accuracy = 0.9400\n",
      "Elapsed time = 1777.77 milliseconds (29.63 per batch)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "Number of parameters: 431080 (Teacher) -> 39760 (Student)\n",
      "Model Size: 1.65 MB (Teacher) -> 0.15 MB (Student)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test model performance after distillation\n",
    "print(\"Teacher model performance:\")\n",
    "general.test(teacher_model, device,  test_loader, criterion=F.nll_loss, epoch=1, metric = metrics.accuracy)\n",
    "print(\"Student model performance:\")\n",
    "general.test(student_model, device,  test_loader, criterion=F.nll_loss, epoch=1, metric = metrics.accuracy)\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "# Compare the number of parameters of the teacher and student model\n",
    "teacher_params = eval.get_model_parameters(teacher_model)\n",
    "student_params = eval.get_model_parameters(student_model)\n",
    "print('Number of parameters: {} (Teacher) -> {} (Student)'.format(teacher_params, student_params))\n",
    "\n",
    "# Compare the model size of the teacher and student model\n",
    "teacher_size = eval.get_model_size(teacher_model)\n",
    "student_size = eval.get_model_size(student_model)\n",
    "print('Model Size: {} MB (Teacher) -> {} MB (Student)'.format(teacher_size, student_size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff67d639abb31abb6a46275810293efc60456a6edbd614d8502142bf104bd3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
