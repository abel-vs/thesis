{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 on CIFAR-10\n",
    "This notebook is used to experiment with VGG-16 on CIFAR-10 dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagenet-1k (/workspace/volume/cache/imagenet-1k/default-212aff79ee65f848/1.0.0/a1e9bfc56c3a7350165007d1176b15e9128fcaf9ab972147840529aed3ae52bc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294d353d989149ab9b0bb143aa0cd679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagenet-1k (/workspace/volume/cache/imagenet-1k/default-212aff79ee65f848/1.0.0/a1e9bfc56c3a7350165007d1176b15e9128fcaf9ab972147840529aed3ae52bc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a2a077d0dc4248b92361a6fa3abcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import src.general as general\n",
    "import src.dataset_models as data\n",
    "import src.metrics as metrics\n",
    "import src.evaluation as eval\n",
    "import src.plot as plot\n",
    "import src.compression.distillation as distill\n",
    "import src.compression.pruning as prune\n",
    "import src.compression.quantization as quant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = data.supported_datasets[\"CIFAR-10\"]\n",
    "# Get transforms\n",
    "vgg_cifar10_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Set transforms\n",
    "dataset.set_transforms(vgg_cifar10_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torch.load(\"/workspace/volume/models/vgg16_cifar10.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate before compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:25<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2119\n",
      "Test score: 93.9889\n",
      "Could not calculate FLOPS\n",
      "==================================== RESULTS ===================================\n",
      "Loss: 0.211898\n",
      "Score: 93.988854\n",
      "Time per data point: 10.2065 ms\n",
      "Model Size: 512.33 MB\n",
      "Number of parameters: 134301514\n",
      "Number of MACs: 15499459200\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "before_results = eval.get_results(vgg16, dataset)\n",
    "plot.print_results(**before_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning\n",
    "This section is used to experiment with pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Conv2d' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quant\u001b[39m.\u001b[39;49mfuse_modules(vgg16)\n",
      "File \u001b[0;32m/workspace/experiments/notebooks/../../src/compression/quantization.py:70\u001b[0m, in \u001b[0;36mfuse_modules\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfuse_modules\u001b[39m(model):\n\u001b[1;32m     69\u001b[0m     modules_to_fuse \u001b[39m=\u001b[39m get_modules_to_fuse(model)\n\u001b[0;32m---> 70\u001b[0m     torch\u001b[39m.\u001b[39;49mquantization\u001b[39m.\u001b[39;49mfuse_modules(model, modules_to_fuse, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/fuse_modules.py:152\u001b[0m, in \u001b[0;36mfuse_modules\u001b[0;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfuse_modules\u001b[39m(model, modules_to_fuse, inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, fuser_func\u001b[39m=\u001b[39mfuse_known_modules, fuse_custom_config_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Fuses a list of modules into a single module\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[39m    Fuses only the following sequence of modules:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m _fuse_modules(\n\u001b[1;32m    153\u001b[0m         model,\n\u001b[1;32m    154\u001b[0m         modules_to_fuse,\n\u001b[1;32m    155\u001b[0m         is_qat\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    156\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m    157\u001b[0m         fuser_func\u001b[39m=\u001b[39;49mfuse_known_modules,\n\u001b[1;32m    158\u001b[0m         fuse_custom_config_dict\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/fuse_modules.py:94\u001b[0m, in \u001b[0;36m_fuse_modules\u001b[0;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[39m# Handle case of modules_to_fuse being a list of lists\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m module_list \u001b[39min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m---> 94\u001b[0m         _fuse_modules_helper(model, module_list, is_qat, fuser_func, fuse_custom_config_dict)\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/fuse_modules.py:75\u001b[0m, in \u001b[0;36m_fuse_modules_helper\u001b[0;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     73\u001b[0m mod_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m---> 75\u001b[0m     mod_list\u001b[39m.\u001b[39mappend(_get_module(model, item))\n\u001b[1;32m     77\u001b[0m \u001b[39m# Fuse list of modules\u001b[39;00m\n\u001b[1;32m     78\u001b[0m new_mod_list \u001b[39m=\u001b[39m fuser_func(mod_list, is_qat, additional_fuser_method_mapping)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/fuse_modules.py:16\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(model, submodule_key)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_module\u001b[39m(model, submodule_key):\n\u001b[0;32m---> 16\u001b[0m     tokens \u001b[39m=\u001b[39m submodule_key\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     cur_mod \u001b[39m=\u001b[39m model\n\u001b[1;32m     18\u001b[0m     \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m tokens:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Conv2d' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "quant.fuse_modules(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = general.get_device()\n",
    "vgg16.to(device)\n",
    "pruned_model = prune.magnitude_pruning_structured(vgg16, dataset, 0.5, fineTune=False, iterative_steps=10, layers=vgg16.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_results = eval.get_results(pruned_model, dataset)\n",
    "plot.print_before_after_results(before_results, after_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general.finetune(pruned_model, dataset, target=99, max_it=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model, \"/workspace/volume/models/vgg16_cifar10_pruned_10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_pruned_model = torch.load(\"/workspace/volume/models/vgg16_cifar10_pruned_v.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results = eval.get_results(old_pruned_model, dataset)\n",
    "plot.print_results(**old_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general.train(old_pruned_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model, \"/workspace/volume/models/vgg16_cifar10_pruned_50.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a new model\n",
    "vgg16 = torch.load(\"/workspace/volume/models/vgg16_cifar10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = quant.static_quantization(vgg16, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = general.get_example_inputs(dataset.train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.eval()\n",
    "fused_model = quant.fuse_modules(vgg16)\n",
    "fused_model(example_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "quantized_results = eval.get_results(quantized_model, dataset, device)\n",
    "plot.print_results(**quantized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.print_before_after_results(before_results, quantized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quantized_model, \"/workspace/volume/models/vgg16_cifar10_dynamic_quantized.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
