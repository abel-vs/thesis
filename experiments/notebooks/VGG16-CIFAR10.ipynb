{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 on CIFAR-10\n",
    "This notebook is used to experiment with VGG-16 on CIFAR-10 dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import src.general as general\n",
    "import src.dataset_models as data\n",
    "import src.metrics as metrics\n",
    "import src.evaluation as eval\n",
    "import src.plot as plot\n",
    "import src.compression.distillation as distill\n",
    "import src.compression.pruning as prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "vgg_weights = tv.models.VGG16_Weights.DEFAULT\n",
    "vgg16 = tv.models.vgg16(weights=vgg_weights)\n",
    "# Modify the last layer to have 10 output classes (CIFAR-10 has 10 classes)\n",
    "vgg16.classifier[6] = nn.Linear(4096, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from a checkpoint\n",
    "checkpoint = torch.load(\"/workspace/volume/models/vgg16_cifar10.pt\")\n",
    "vgg16.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = data.supported_datasets[\"CIFAR-10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms\n",
    "vgg_cifar10_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Set transforms\n",
    "dataset.set_transforms(vgg_cifar10_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:26<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2082\n",
      "Test score: 93.9689\n",
      "Could not calculate FLOPS\n"
     ]
    }
   ],
   "source": [
    "before_results = eval.get_results(vgg16, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== RESULTS ===================================\n",
      "Loss: 0.208209\n",
      "Score: 93.968949\n",
      "Time per data point: 10.4277 ms\n",
      "Model Size: 512.33 MB\n",
      "Number of parameters: 134301514\n",
      "Number of MACs: 15499459200\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "plot.print_results(**before_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n"
     ]
    }
   ],
   "source": [
    "ignored_layers = prune.get_layers_not_to_prune(vgg16.features)\n",
    "print(ignored_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = general.get_example_inputs(dataset.train_loader)\n",
    "input_batch = next(iter(dataset.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           ...,\n",
       "           [-2.1179, -2.1179, -0.2513,  ..., -0.5767, -0.5767, -0.5767],\n",
       "           [-2.1179, -2.1179, -0.2342,  ..., -0.5938, -0.5938, -0.5938],\n",
       "           [-2.1179, -2.1179, -0.2342,  ..., -0.5938, -0.5938, -0.5938]],\n",
       " \n",
       "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           ...,\n",
       "           [-2.0357, -2.0357,  0.1527,  ..., -0.2325, -0.2325, -0.2325],\n",
       "           [-2.0357, -2.0357,  0.1527,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-2.0357, -2.0357,  0.1527,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044, -0.7238,  ..., -1.0201, -1.0201, -1.0201],\n",
       "           [-1.8044, -1.8044, -0.7064,  ..., -1.0201, -1.0201, -1.0201],\n",
       "           [-1.8044, -1.8044, -0.7064,  ..., -1.0201, -1.0201, -1.0201]]],\n",
       " \n",
       " \n",
       "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [ 0.7762,  0.7762,  0.7591,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [ 0.7762,  0.7762,  0.7591,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           ...,\n",
       "           [-1.8953, -1.9124, -1.9295,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-1.8953, -1.9124, -1.9295,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-1.8953, -1.9124, -1.9295,  ..., -2.1179, -2.1179, -2.1179]],\n",
       " \n",
       "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [ 1.0805,  1.0805,  1.0805,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [ 1.0805,  1.0805,  1.0805,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           ...,\n",
       "           [-1.8081, -1.8256, -1.8256,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-1.8081, -1.8256, -1.8256,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-1.8081, -1.8256, -1.8256,  ..., -2.0357, -2.0357, -2.0357]],\n",
       " \n",
       "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [ 1.9254,  1.9254,  1.9080,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [ 1.9254,  1.9254,  1.9080,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [-1.4907, -1.5081, -1.5256,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.4907, -1.5081, -1.5256,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.4907, -1.5081, -1.5256,  ..., -1.8044, -1.8044, -1.8044]]],\n",
       " \n",
       " \n",
       "         [[[-0.6623, -0.6623, -0.6623,  ..., -0.2171, -0.2171, -0.2171],\n",
       "           [-0.6623, -0.6623, -0.6623,  ..., -0.2171, -0.2171, -0.2171],\n",
       "           [-0.6623, -0.6623, -0.6623,  ..., -0.2171, -0.2171, -0.2171],\n",
       "           ...,\n",
       "           [ 0.0912,  0.0912,  0.0912,  ...,  2.0092,  2.0092,  2.0092],\n",
       "           [ 0.0912,  0.0912,  0.0912,  ...,  2.0092,  2.0092,  2.0092],\n",
       "           [ 0.0912,  0.0912,  0.0912,  ...,  2.0092,  2.0092,  2.0092]],\n",
       " \n",
       "          [[-0.3375, -0.3375, -0.3375,  ...,  0.0826,  0.0826,  0.0826],\n",
       "           [-0.3375, -0.3375, -0.3375,  ...,  0.0826,  0.0826,  0.0826],\n",
       "           [-0.3375, -0.3375, -0.3375,  ...,  0.0826,  0.0826,  0.0826],\n",
       "           ...,\n",
       "           [ 0.1702,  0.1702,  0.1702,  ...,  2.1660,  2.1660,  2.1660],\n",
       "           [ 0.1702,  0.1702,  0.1702,  ...,  2.1660,  2.1660,  2.1660],\n",
       "           [ 0.1702,  0.1702,  0.1702,  ...,  2.1660,  2.1660,  2.1660]],\n",
       " \n",
       "          [[ 0.0953,  0.0953,  0.0953,  ..., -0.1661, -0.1661, -0.1661],\n",
       "           [ 0.0953,  0.0953,  0.0953,  ..., -0.1661, -0.1661, -0.1661],\n",
       "           [ 0.0953,  0.0953,  0.0953,  ..., -0.1661, -0.1661, -0.1661],\n",
       "           ...,\n",
       "           [ 0.2696,  0.2696,  0.2696,  ...,  1.9603,  1.9603,  1.9603],\n",
       "           [ 0.2696,  0.2696,  0.2696,  ...,  1.9603,  1.9603,  1.9603],\n",
       "           [ 0.2696,  0.2696,  0.2696,  ...,  1.9603,  1.9603,  1.9603]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.1179, -2.1179,  0.3481,  ..., -0.5938, -0.5253, -0.5253],\n",
       "           [-2.1179, -2.1179,  0.3481,  ..., -0.5938, -0.5253, -0.5253],\n",
       "           [-2.1179, -2.1179,  0.3481,  ..., -0.5938, -0.5253, -0.5253],\n",
       "           ...,\n",
       "           [-2.1179, -2.1179,  0.1939,  ...,  0.1597,  0.2111,  0.2111],\n",
       "           [-2.1179, -2.1179,  0.1939,  ...,  0.1597,  0.2111,  0.2111],\n",
       "           [-2.1179, -2.1179,  0.1939,  ...,  0.1597,  0.2111,  0.2111]],\n",
       " \n",
       "          [[-2.0357, -2.0357,  0.5028,  ..., -0.4076, -0.3375, -0.3375],\n",
       "           [-2.0357, -2.0357,  0.5028,  ..., -0.4076, -0.3375, -0.3375],\n",
       "           [-2.0357, -2.0357,  0.5028,  ..., -0.4076, -0.3375, -0.3375],\n",
       "           ...,\n",
       "           [-2.0357, -2.0357,  0.2752,  ...,  0.1702,  0.2227,  0.2227],\n",
       "           [-2.0357, -2.0357,  0.2752,  ...,  0.1702,  0.2227,  0.2227],\n",
       "           [-2.0357, -2.0357,  0.2752,  ...,  0.1702,  0.2227,  0.2227]],\n",
       " \n",
       "          [[-1.8044, -1.8044,  0.0779,  ..., -0.2532, -0.2010, -0.2010],\n",
       "           [-1.8044, -1.8044,  0.0779,  ..., -0.2532, -0.2010, -0.2010],\n",
       "           [-1.8044, -1.8044,  0.0779,  ..., -0.2532, -0.2010, -0.2010],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044,  0.1825,  ...,  0.2522,  0.3045,  0.3045],\n",
       "           [-1.8044, -1.8044,  0.1825,  ...,  0.2522,  0.3045,  0.3045],\n",
       "           [-1.8044, -1.8044,  0.1825,  ...,  0.2522,  0.3045,  0.3045]]],\n",
       " \n",
       " \n",
       "         [[[-2.1179,  0.7933,  0.7933,  ...,  0.7248,  0.7248,  0.7248],\n",
       "           [-2.1179,  0.8276,  0.8276,  ...,  0.7419,  0.7419,  0.7419],\n",
       "           [-2.1179,  0.8447,  0.8447,  ...,  0.7762,  0.7762,  0.7762],\n",
       "           ...,\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       " \n",
       "          [[-2.0357,  0.8529,  0.8529,  ...,  0.8529,  0.8529,  0.8529],\n",
       "           [-2.0357,  0.8880,  0.8880,  ...,  0.8704,  0.8704,  0.8704],\n",
       "           [-2.0357,  0.9055,  0.9055,  ...,  0.9055,  0.9055,  0.9055],\n",
       "           ...,\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       " \n",
       "          [[-1.8044,  1.2282,  1.2282,  ...,  1.2108,  1.2108,  1.2108],\n",
       "           [-1.8044,  1.2457,  1.2457,  ...,  1.2282,  1.2282,  1.2282],\n",
       "           [-1.8044,  1.2805,  1.2805,  ...,  1.2457,  1.2457,  1.2457],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
       " \n",
       " \n",
       "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           ...,\n",
       "           [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
       "           [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
       "           [-1.1418, -1.1418, -1.1418,  ..., -1.1418, -1.1418, -1.1418]],\n",
       " \n",
       "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           ...,\n",
       "           [-0.8452, -0.8452, -0.8452,  ..., -0.9853, -0.9853, -0.9853],\n",
       "           [-0.8627, -0.8627, -0.8627,  ..., -0.9853, -0.9853, -0.9853],\n",
       "           [-0.8627, -0.8627, -0.8627,  ..., -1.0028, -1.0028, -1.0028]],\n",
       " \n",
       "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [-0.1138, -0.1138, -0.1138,  ..., -0.7587, -0.7587, -0.7587],\n",
       "           [-0.1312, -0.1312, -0.1312,  ..., -0.7587, -0.7587, -0.7587],\n",
       "           [-0.1312, -0.1312, -0.1312,  ..., -0.7761, -0.7761, -0.7761]]]]),\n",
       " tensor([1, 8, 7, 7, 8, 5, 1, 6, 7, 9, 4, 6, 9, 2, 3, 7, 6, 2, 9, 0, 3, 8, 0, 7,\n",
       "         9, 8, 0, 0, 1, 7, 0, 4, 6, 5, 4, 1, 0, 3, 3, 8, 2, 0, 6, 0, 4, 9, 3, 3,\n",
       "         2, 7, 1, 3, 8, 2, 3, 5, 9, 9, 9, 3, 9, 1, 4, 2])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = data.supported_datasets[\"MNIST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general.get_example_inputs(mnist.train_loader).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(general.get_example_input_batch(dataset.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (list, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_pruning/dependency.py:511\u001b[0m, in \u001b[0;36mDependencyGraph._trace\u001b[0;34m(self, model, example_inputs, forward_fn, output_transform)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     out \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49mexample_inputs)\n\u001b[1;32m    512\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pruned_model \u001b[39m=\u001b[39m prune\u001b[39m.\u001b[39;49mmagnitude_pruning_structured(vgg16, dataset, \u001b[39m0.5\u001b[39;49m, fineTune\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, iterative_steps\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, layers\u001b[39m=\u001b[39;49mvgg16\u001b[39m.\u001b[39;49mfeatures)\n",
      "File \u001b[0;32m/workspace/experiments/notebooks/../../src/compression/pruning.py:84\u001b[0m, in \u001b[0;36mmagnitude_pruning_structured\u001b[0;34m(model, dataset, sparsity, fineTune, iterative_steps, layers)\u001b[0m\n\u001b[1;32m     81\u001b[0m     ignored_layers \u001b[39m=\u001b[39m get_layers_not_to_prune(layers)\n\u001b[1;32m     83\u001b[0m \u001b[39m# 2. Pruner initialization\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m pruner \u001b[39m=\u001b[39m tp\u001b[39m.\u001b[39;49mpruner\u001b[39m.\u001b[39;49mMagnitudePruner(\n\u001b[1;32m     85\u001b[0m     model,\n\u001b[1;32m     86\u001b[0m     example_inputs,\n\u001b[1;32m     87\u001b[0m     \u001b[39m# If False, a uniform sparsity will be assigned to different layers.\u001b[39;49;00m\n\u001b[1;32m     88\u001b[0m     global_pruning\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     89\u001b[0m     importance\u001b[39m=\u001b[39;49mimp,  \u001b[39m# importance criterion for parameter selection\u001b[39;49;00m\n\u001b[1;32m     90\u001b[0m     \u001b[39m# the number of iterations to achieve target sparsity\u001b[39;49;00m\n\u001b[1;32m     91\u001b[0m     iterative_steps\u001b[39m=\u001b[39;49miterative_steps,\n\u001b[1;32m     92\u001b[0m     ch_sparsity\u001b[39m=\u001b[39;49msparsity,\n\u001b[1;32m     93\u001b[0m     ignored_layers\u001b[39m=\u001b[39;49mignored_layers,\n\u001b[1;32m     94\u001b[0m )\n\u001b[1;32m     96\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterative_steps):\n\u001b[1;32m     97\u001b[0m     \u001b[39m# pruner.step will remove some channels from the model with least importance\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     pruner\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_pruning/pruner/algorithms/metapruner.py:62\u001b[0m, in \u001b[0;36mMetaPruner.__init__\u001b[0;34m(self, model, example_inputs, importance, global_pruning, ch_sparsity, ch_sparsity_dict, max_ch_sparsity, iterative_steps, iterative_sparsity_scheduler, ignored_layers, round_to, channel_groups, customized_pruners, unwrapped_parameters, root_module_types, output_transform)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_to \u001b[39m=\u001b[39m round_to\n\u001b[1;32m     61\u001b[0m \u001b[39m# Build dependency graph\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDG \u001b[39m=\u001b[39m dependency\u001b[39m.\u001b[39;49mDependencyGraph()\u001b[39m.\u001b[39;49mbuild_dependency(\n\u001b[1;32m     63\u001b[0m     model,\n\u001b[1;32m     64\u001b[0m     example_inputs\u001b[39m=\u001b[39;49mexample_inputs,\n\u001b[1;32m     65\u001b[0m     output_transform\u001b[39m=\u001b[39;49moutput_transform,\n\u001b[1;32m     66\u001b[0m     unwrapped_parameters\u001b[39m=\u001b[39;49munwrapped_parameters,\n\u001b[1;32m     67\u001b[0m     customized_pruners\u001b[39m=\u001b[39;49mcustomized_pruners,\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignored_layers \u001b[39m=\u001b[39m []  \n\u001b[1;32m     71\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m ignored_layers:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_pruning/dependency.py:254\u001b[0m, in \u001b[0;36mDependencyGraph.build_dependency\u001b[0;34m(self, model, example_inputs, forward_fn, output_transform, unwrapped_parameters, customized_pruners, verbose)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[39mif\u001b[39;00m sub_module\u001b[39m!=\u001b[39mm: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mIGNORED_LAYERS\u001b[39m.\u001b[39mappend(sub_module)\n\u001b[1;32m    253\u001b[0m \u001b[39m# Build computational graph by tracing.\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule2node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trace(\n\u001b[1;32m    255\u001b[0m     model, example_inputs, forward_fn, output_transform\u001b[39m=\u001b[39;49moutput_transform\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m \u001b[39m# Build the dependency graph\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_dependency(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule2node)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_pruning/dependency.py:513\u001b[0m, in \u001b[0;36mDependencyGraph._trace\u001b[0;34m(self, model, example_inputs, forward_fn, output_transform)\u001b[0m\n\u001b[1;32m    511\u001b[0m         out \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39mexample_inputs)\n\u001b[1;32m    512\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         out \u001b[39m=\u001b[39m model(example_inputs)\n\u001b[1;32m    515\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m hooks:\n\u001b[1;32m    516\u001b[0m     hook\u001b[39m.\u001b[39mremove()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 66\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     67\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m     68\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (list, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "pruned_model = prune.magnitude_pruning_structured(vgg16, dataset, 0.5, fineTune=False, iterative_steps=5, layers=vgg16.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:25<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2122\n",
      "Test score: 93.6306\n",
      "Could not calculate FLOPS\n"
     ]
    }
   ],
   "source": [
    "after_results = eval.get_results(pruned_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= RESULTS BEFORE & AFTER ===========================\n",
      "Loss: 0.207255 -> 0.212175 (2.37%)\n",
      "Score: 93.859475 -> 93.630573 (-0.24%)\n",
      "Time per data point: 10.3823 ms -> 10.3398 ms (-0.41%)\n",
      "Model Size: 512.33 MB -> 512.33 MB (-0.00%)\n",
      "Number of parameters: 134301514 -> 134301514 (-0.00%)\n",
      "Number of MACs: 15499459200 -> 15499459200 (-0.00%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "plot.print_before_after_results(before_results, after_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), \"/workspace/volume/models/vgg16_cifar10_pruned_50.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
