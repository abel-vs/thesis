{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 on CIFAR-10\n",
    "This notebook is used to experiment with VGG-16 on CIFAR-10 dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagenet-1k (/workspace/volume/cache/imagenet-1k/default-212aff79ee65f848/1.0.0/a1e9bfc56c3a7350165007d1176b15e9128fcaf9ab972147840529aed3ae52bc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7718fe74513c4922959ef122b522b322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagenet-1k (/workspace/volume/cache/imagenet-1k/default-212aff79ee65f848/1.0.0/a1e9bfc56c3a7350165007d1176b15e9128fcaf9ab972147840529aed3ae52bc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b22af8596014c47b1c66d2d92f79c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import src.general as general\n",
    "import src.dataset_models as data\n",
    "import src.metrics as metrics\n",
    "import src.evaluation as eval\n",
    "import src.plot as plot\n",
    "import src.compression.distillation as distill\n",
    "import src.compression.pruning as prune\n",
    "import src.compression.quantization as quant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = data.supported_datasets[\"CIFAR-10\"]\n",
    "# Get transforms\n",
    "vgg_cifar10_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Set transforms\n",
    "dataset.set_transforms(vgg_cifar10_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torch.load(\"/workspace/volume/models/vgg16_cifar10.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate before compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:26<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2099\n",
      "Test score: 93.9889\n",
      "==================================== RESULTS ===================================\n",
      "Loss: 0.209863\n",
      "Score: 93.988854\n",
      "Time per data point: 10.4772 ms\n",
      "Model Size: 512.33 MB\n",
      "Number of parameters: 134301514\n",
      "Number of MACs: 15499459200\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "before_results = eval.get_results(vgg16, dataset)\n",
    "plot.print_results(**before_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning\n",
    "This section is used to experiment with pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant.fuse_modules(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = general.get_device()\n",
    "vgg16.to(device)\n",
    "pruned_model = prune.channel_pruning(vgg16, dataset, 0.5, fineTune=True, iterative_steps=10, layers=vgg16.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model, \"/workspace/volume/models/vgg16_cifar10_pruned_50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = torch.load(\"/workspace/volume/models/vgg16_cifar10_pruned_50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general.validate(pruned_model, dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load teacher and student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = torch.load(\"/workspace/volume/models/vgg16_cifar10.pt\")\n",
    "student = torch.load(\"/workspace/volume/models/vgg16_cifar10_pruned_50.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance before distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:26<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2146\n",
      "Test score: 94.0585\n",
      "Could not calculate FLOPS\n",
      "==================================== RESULTS ===================================\n",
      "Loss: 0.214559\n",
      "Score: 94.058519\n",
      "Time per data point: 10.5894 ms\n",
      "Model Size: 512.33 MB\n",
      "Number of parameters: 134301514\n",
      "Number of MACs: 15499459200\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "teacher_results = eval.get_results(teacher, dataset)\n",
    "plot.print_results(**teacher_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:16<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4197\n",
      "Test score: 86.4351\n",
      "Could not calculate FLOPS\n",
      "==================================== RESULTS ===================================\n",
      "Loss: 0.419710\n",
      "Score: 86.435111\n",
      "Time per data point: 6.4991 ms\n",
      "Model Size: 242.15 MB\n",
      "Number of parameters: 63475626\n",
      "Number of MACs: 3934750048\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "student_results = eval.get_results(student, dataset)\n",
    "plot.print_results(**student_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"epochs\": 3,\n",
    "    \"distil_technique\": distill.soft_target_distillation,\n",
    "    \"distil_loss\": F.kl_div,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = distill.perform_distillation(teacher, dataset, student_model=student, settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 157/157 [00:15<00:00,  9.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3126\n",
      "Test score: 90.0279\n",
      "============================= RESULTS BEFORE & AFTER ===========================\n",
      "Loss: 0.214559 -> 0.312607 (45.70%)\n",
      "Score: 94.058519 -> 90.027866 (-4.29%)\n",
      "Time per data point: 10.5894 ms -> 6.3684 ms (-39.86%)\n",
      "Model Size: 512.33 MB -> 242.15 MB (-52.74%)\n",
      "Number of parameters: 134301514 -> 63475626 (-52.74%)\n",
      "Number of MACs: 15499459200 -> 3934750048 (-74.61%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "student_results = eval.get_results(student, dataset)\n",
    "plot.print_before_after_results(teacher_results, student_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_results = eval.get_results(student, dataset)\n",
    "plot.print_before_after_results(teacher_results, student_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general.finetune(pruned_model, dataset, target=99, max_it=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student, \"/workspace/volume/models/vgg16_cifar10_distilled.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torch.load(\"/workspace/volume/models/vgg16_cifar10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = quant.static_quantization(vgg16, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "quantized_results = eval.get_results(quantized_model, dataset, device)\n",
    "plot.print_results(**quantized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.print_before_after_results(before_results, quantized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quantized_model, \"/workspace/volume/models/vgg16_cifar10_dynamic_quantized.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
